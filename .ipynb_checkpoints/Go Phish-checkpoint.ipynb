{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38595281-ff4b-45f8-9125-0637a46304f1",
   "metadata": {},
   "source": [
    "Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "493bbe0e-460c-4fa7-8261-8c7115ad9b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab_Size: 50550 NumSpam: 1500 NumHam: 3672 MaxSequenceLen: 3568\n",
      "tensor([   0, 2971, 9849,  ...,    0,    0,    0]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Define path to data\n",
    "data_dir = 'enron1'\n",
    "\n",
    "# Define categories\n",
    "categories = ['ham', 'spam']\n",
    "num_categories = len(categories)\n",
    "\n",
    "# Define dataset class\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "# Initialize variables\n",
    "docs = []\n",
    "labels = []\n",
    "categories_to_count = {'ham': 0, 'spam' : 0}\n",
    "\n",
    "# Load data\n",
    "for category in categories:\n",
    "    # Get list of files\n",
    "    path = os.path.join(data_dir, category)\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    for file in files:\n",
    "        # Read file\n",
    "        with open(os.path.join(path, file), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text = f.read()\n",
    "            \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Add to docs and labels\n",
    "        docs.append(text)\n",
    "        labels.append(category)\n",
    "        categories_to_count[category] = categories_to_count[category]+1\n",
    "        \n",
    "# Tokenize text\n",
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "for doc in docs:\n",
    "    for word in doc.split():\n",
    "        if word not in word_to_idx:\n",
    "            idx = len(word_to_idx)\n",
    "            word_to_idx[word] = idx\n",
    "            idx_to_word[idx] = word\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "\n",
    "# Convert text to sequence of indices\n",
    "sequences = []\n",
    "for doc in docs:\n",
    "    sequence = [word_to_idx[word] for word in doc.split()]\n",
    "    sequences.append(sequence)\n",
    "\n",
    "# Pad sequences to be of equal length\n",
    "max_len = max([len(seq) for seq in sequences])\n",
    "padded_sequences = []\n",
    "for seq in sequences:\n",
    "    seq = torch.LongTensor(seq)\n",
    "    padded_seq = torch.zeros(max_len, dtype=torch.long)\n",
    "    padded_seq[:len(seq)] = seq\n",
    "    padded_sequences.append(padded_seq)\n",
    "    \n",
    "# Convert labels to categorical\n",
    "cat_labels = torch.tensor([categories.index(label) for label in labels], dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Vocab_Size:\", vocab_size, \"NumSpam:\", categories_to_count['spam'], \"NumHam:\", categories_to_count['ham'] , \"MaxSequenceLen:\", max_len)\n",
    "print(padded_sequences[1000], cat_labels[1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f566ec-142a-43c3-b7b8-1471b28547b7",
   "metadata": {},
   "source": [
    "Define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4264724f-dc41-42b2-9efe-4eb7b77f4e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 3103 Test Size: 1035 Validation Size: 1034\n"
     ]
    }
   ],
   "source": [
    "train_percent = .6\n",
    "test_percent = .2\n",
    "validation_percent = .2\n",
    "\n",
    "# Split data into train, test, and validation sets\n",
    "train_data, test_val_data, train_labels, test_val_labels = train_test_split(padded_sequences, cat_labels, test_size=test_percent+validation_percent, stratify=cat_labels)\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(test_val_data, test_val_labels, test_size=test_percent/(test_percent+validation_percent), stratify=test_val_labels)\n",
    "\n",
    "\n",
    "train_dataset = EmailDataset(train_data, train_labels)\n",
    "test_dataset = EmailDataset(test_data, test_labels)\n",
    "validation_dataset = EmailDataset(val_data, val_labels)\n",
    "\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(\"Train Size:\", len(train_dataset), \"Test Size:\", len(test_dataset), \"Validation Size:\", len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20f349-edac-4a42-93ae-bdcdb655b2d1",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a9ac305-c3cd-454d-98c6-054a6bfc6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class WordLSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, output_size, batch_size):\n",
    "        super(WordLSTM, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # shape is batch_size, seq_len, \n",
    "        out, hn = self.lstm(x, h)\n",
    "        #print(out.size())\n",
    "        #print(out[:,-1].size())\n",
    "        # only pass in last out\n",
    "        out = self.fc(out[:, -1])\n",
    "        out = self.activation(out)\n",
    "        return torch.squeeze(out, dim=1), hn\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a4036-e347-4f18-a0b6-2970efab3caf",
   "metadata": {},
   "source": [
    "Initialize Cuda if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e26f35cc-1cb1-4b6a-b448-56f74d00a495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    print(torch.__version__)\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3baafb-e827-49f4-b689-d32558a46241",
   "metadata": {},
   "source": [
    "Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "faa444f5-f640-426c-932c-99ad4d6d2bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordLSTM(\n",
      "  (embedding): Embedding(50550, 100)\n",
      "  (lstm): LSTM(100, 15, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n",
      "5063956\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "hidden_size = 15\n",
    "embedding_size = 100\n",
    "num_layers = 2\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = WordLSTM(vocab_size, embedding_size, hidden_size, num_layers, 1, batch_size)\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(sum(p.numel() for p in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd2928-5ad8-4c42-ad74-d570264cdc49",
   "metadata": {},
   "source": [
    "Initialize Model and Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e46eea7-56ca-4b1d-b43d-f8928bdbaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.03\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.5, patience = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af84bd-e34a-4486-9849-8a1ea899ac21",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "641663c6-e3cb-4cfc-be4b-570ddf231fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4166], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "0 out of 3103 batches trained. Average loss so far: 0.5388124585151672\n",
      "tensor([0.4140], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4098], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4041], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3971], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3936], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3887], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3825], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3798], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3802], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3788], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "10 out of 3103 batches trained. Average loss so far: 0.6288857053626667\n",
      "tensor([0.3758], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3760], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3789], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3799], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3790], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3765], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3726], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3674], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3656], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3667], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "20 out of 3103 batches trained. Average loss so far: 0.6527900497118632\n",
      "tensor([0.3662], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3640], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3605], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3557], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3498], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3431], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3399], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3356], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3303], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3241], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "30 out of 3103 batches trained. Average loss so far: 0.6006747541889068\n",
      "tensor([0.3173], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3140], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3098], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3048], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2990], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2927], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2859], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2826], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2826], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2814], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "40 out of 3103 batches trained. Average loss so far: 0.6039019597739708\n",
      "tensor([0.2793], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2763], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2725], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2681], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2631], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2577], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2557], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2529], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2495], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2492], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "50 out of 3103 batches trained. Average loss so far: 0.6091522884135153\n",
      "tensor([0.2517], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2567], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2602], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2625], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2674], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2707], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2766], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2809], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2837], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2851], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "60 out of 3103 batches trained. Average loss so far: 0.6269138274622745\n",
      "tensor([0.2892], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2957], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3045], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3114], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3204], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3274], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3323], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3353], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3366], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3406], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "70 out of 3103 batches trained. Average loss so far: 0.6477738400580177\n",
      "tensor([0.3471], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3559], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3667], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3749], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3806], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3841], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3901], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3937], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3951], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3946], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "80 out of 3103 batches trained. Average loss so far: 0.6474699304427629\n",
      "tensor([0.3923], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3885], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3833], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3769], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3694], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3612], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3522], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3427], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3327], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3225], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "90 out of 3103 batches trained. Average loss so far: 0.6258025090773027\n",
      "tensor([0.3120], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3015], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2910], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2806], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2704], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2603], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2505], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2410], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2318], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2229], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "100 out of 3103 batches trained. Average loss so far: 0.5945639816841276\n",
      "tensor([0.2144], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2095], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2077], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2086], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2120], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2143], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2158], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2164], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2162], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2154], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "110 out of 3103 batches trained. Average loss so far: 0.621965467124372\n",
      "tensor([0.2172], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2214], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2279], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2330], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2369], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2396], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2448], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2486], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2549], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2596], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "120 out of 3103 batches trained. Average loss so far: 0.6327540761183116\n",
      "tensor([0.2629], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2650], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2696], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2766], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2819], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2857], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2879], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2888], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2925], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2946], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "130 out of 3103 batches trained. Average loss so far: 0.6385358772205032\n",
      "tensor([0.2994], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3065], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3118], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3153], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3172], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3175], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3165], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3143], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3109], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3067], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "140 out of 3103 batches trained. Average loss so far: 0.6315491873744532\n",
      "tensor([0.3057], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3036], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3005], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2965], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2917], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2863], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2803], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2739], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2711], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2674], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "150 out of 3103 batches trained. Average loss so far: 0.6253332280560046\n",
      "tensor([0.2670], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2656], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2633], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2640], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2675], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2696], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2704], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2702], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2689], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2668], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "160 out of 3103 batches trained. Average loss so far: 0.624850716094793\n",
      "tensor([0.2676], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2712], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2772], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2816], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2845], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2860], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2863], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2853], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2834], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2805], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "170 out of 3103 batches trained. Average loss so far: 0.6192217861351214\n",
      "tensor([0.2769], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2725], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2676], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2660], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2636], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2604], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2566], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2522], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2511], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2492], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "180 out of 3103 batches trained. Average loss so far: 0.619430920531078\n",
      "tensor([0.2502], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2538], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2562], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2611], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2646], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2668], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2677], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2675], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2664], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2681], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "190 out of 3103 batches trained. Average loss so far: 0.619556952521439\n",
      "tensor([0.2686], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2681], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2666], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2680], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2683], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2675], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2696], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2744], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2776], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2794], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "200 out of 3103 batches trained. Average loss so far: 0.6241634734234407\n",
      "tensor([0.2839], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2868], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2923], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2962], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2984], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2993], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2988], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3012], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3022], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3019], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "210 out of 3103 batches trained. Average loss so far: 0.6195842383597134\n",
      "tensor([0.3003], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3017], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3018], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3048], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3103], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3140], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3161], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3166], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3157], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3136], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "220 out of 3103 batches trained. Average loss so far: 0.619661696221494\n",
      "tensor([0.3105], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3063], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3014], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2998], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2972], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2977], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2969], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2950], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2962], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2960], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "230 out of 3103 batches trained. Average loss so far: 0.6193961343723974\n",
      "tensor([0.2947], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2923], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2890], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2888], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2876], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2893], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2896], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2928], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2945], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2949], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "240 out of 3103 batches trained. Average loss so far: 0.6228257794845153\n",
      "tensor([0.2981], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2997], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3000], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2990], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2969], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2938], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2939], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2928], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2906], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2875], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "250 out of 3103 batches trained. Average loss so far: 0.6154457124105963\n",
      "tensor([0.2836], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2790], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2738], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2681], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2658], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2628], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2628], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2619], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2601], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2575], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "260 out of 3103 batches trained. Average loss so far: 0.615655127042098\n",
      "tensor([0.2579], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2611], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2629], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2636], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2633], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2620], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2598], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2569], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2570], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2600], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "270 out of 3103 batches trained. Average loss so far: 0.6158070874390127\n",
      "tensor([0.2616], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2621], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2654], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2712], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2793], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2855], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2901], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2972], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3065], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3179], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "280 out of 3103 batches trained. Average loss so far: 0.6257544180040258\n",
      "tensor([0.3270], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3382], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3469], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3533], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3576], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3599], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3603], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3591], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3609], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3653], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "290 out of 3103 batches trained. Average loss so far: 0.6275444820369642\n",
      "tensor([0.3722], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3813], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3878], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3919], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3984], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4025], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4042], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4086], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4107], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4106], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "300 out of 3103 batches trained. Average loss so far: 0.6279828879128263\n",
      "tensor([0.4086], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4049], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3997], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3932], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3902], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3857], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3799], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3730], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3696], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3694], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "310 out of 3103 batches trained. Average loss so far: 0.628338462670133\n",
      "tensor([0.3676], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3688], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3683], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3661], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3670], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3706], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3768], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3806], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3869], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3908], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "320 out of 3103 batches trained. Average loss so far: 0.6316414769750518\n",
      "tensor([0.3926], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3923], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3903], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3913], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3904], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3878], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3883], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3869], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3885], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3882], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "330 out of 3103 batches trained. Average loss so far: 0.6315925531877131\n",
      "tensor([0.3861], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3824], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3820], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3798], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3762], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3712], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3651], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3580], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3545], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3499], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "340 out of 3103 batches trained. Average loss so far: 0.6297679039215412\n",
      "tensor([0.3441], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3375], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3302], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3223], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3139], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3051], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2961], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2910], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2853], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2790], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "350 out of 3103 batches trained. Average loss so far: 0.6248967604249971\n",
      "tensor([0.2724], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2655], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2584], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2512], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2439], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2366], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2293], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2221], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2151], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2081], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "360 out of 3103 batches trained. Average loss so far: 0.6189098236798579\n",
      "tensor([0.2046], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2039], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2027], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2040], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2046], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2046], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2038], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2025], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2007], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1985], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "370 out of 3103 batches trained. Average loss so far: 0.6156957544727788\n",
      "tensor([0.1959], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1960], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1986], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2003], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2013], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2015], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2011], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2032], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2077], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2111], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "380 out of 3103 batches trained. Average loss so far: 0.6235261916175602\n",
      "tensor([0.2168], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2212], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2280], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2334], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2375], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2404], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2457], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2497], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2561], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2610], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "390 out of 3103 batches trained. Average loss so far: 0.6235425373172516\n",
      "tensor([0.2644], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2704], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2747], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2815], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2866], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2941], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3038], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3114], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3170], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3251], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "400 out of 3103 batches trained. Average loss so far: 0.6279890760965181\n",
      "tensor([0.3310], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3349], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3413], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3457], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3481], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3488], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3479], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3499], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3502], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3489], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "410 out of 3103 batches trained. Average loss so far: 0.6261915303494808\n",
      "tensor([0.3462], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3423], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3373], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3314], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3247], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3174], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3095], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3013], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2927], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2840], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "420 out of 3103 batches trained. Average loss so far: 0.6204425237382676\n",
      "tensor([0.2752], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2702], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2647], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2626], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2597], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2599], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2591], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2612], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2658], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2690], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "430 out of 3103 batches trained. Average loss so far: 0.6273997860967145\n",
      "tensor([0.2747], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2788], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2815], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2828], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2828], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2818], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2797], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2768], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2731], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2726], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "440 out of 3103 batches trained. Average loss so far: 0.6227936637239392\n",
      "tensor([0.2711], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2687], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2694], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2689], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2713], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2724], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2724], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2752], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2805], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2843], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "450 out of 3103 batches trained. Average loss so far: 0.6268779519788442\n",
      "tensor([0.2905], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2990], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3056], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3104], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3175], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3227], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3260], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3277], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3277], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3307], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "460 out of 3103 batches trained. Average loss so far: 0.6267429475153345\n",
      "tensor([0.3319], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3359], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3424], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3511], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3576], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3618], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3640], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3644], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3631], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3647], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "470 out of 3103 batches trained. Average loss so far: 0.6282183713973708\n",
      "tensor([0.3646], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3629], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3642], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3637], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3661], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3711], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3740], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3794], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3872], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3924], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "480 out of 3103 batches trained. Average loss so far: 0.631328067635796\n",
      "tensor([0.3999], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4095], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4210], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4294], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4350], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4379], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4433], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4460], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4463], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4445], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "490 out of 3103 batches trained. Average loss so far: 0.6325057897936788\n",
      "tensor([0.4455], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4490], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4501], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4489], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4504], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4496], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4468], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4422], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4406], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4372], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "500 out of 3103 batches trained. Average loss so far: 0.6329812263538261\n",
      "tensor([0.4320], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4300], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4262], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4208], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4187], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4148], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4141], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4115], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4072], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4015], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "510 out of 3103 batches trained. Average loss so far: 0.6330126006076014\n",
      "tensor([0.3946], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3865], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3776], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3680], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3578], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3471], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3361], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3250], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3138], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3067], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "520 out of 3103 batches trained. Average loss so far: 0.6306912792049305\n",
      "tensor([0.2991], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2952], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2906], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2853], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2794], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2732], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2704], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2668], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2627], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2580], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "530 out of 3103 batches trained. Average loss so far: 0.6303889011708133\n",
      "tensor([0.2566], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2543], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2514], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2479], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2475], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2462], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2442], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2450], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2449], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2476], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "540 out of 3103 batches trained. Average loss so far: 0.6302401000382499\n",
      "tensor([0.2490], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2495], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2490], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2512], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2524], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2561], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2586], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2598], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2637], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2701], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "550 out of 3103 batches trained. Average loss so far: 0.6319060451106021\n",
      "tensor([0.2748], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2781], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2799], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2805], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2800], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2784], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2759], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2764], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2759], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2743], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "560 out of 3103 batches trained. Average loss so far: 0.6281539372263107\n",
      "tensor([0.2718], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2724], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2757], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2776], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2783], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2817], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2837], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2844], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2839], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2823], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "570 out of 3103 batches trained. Average loss so far: 0.6296359496859869\n",
      "tensor([0.2837], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2839], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2829], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2809], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2780], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2744], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2701], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2652], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2637], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2613], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "580 out of 3103 batches trained. Average loss so far: 0.6260745273502271\n",
      "tensor([0.2582], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2544], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2538], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2524], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2501], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2508], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2506], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2531], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2544], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2546], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "590 out of 3103 batches trained. Average loss so far: 0.6277700501246702\n",
      "tensor([0.2576], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2594], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2600], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2633], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2653], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2661], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2659], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2646], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2625], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2596], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "600 out of 3103 batches trained. Average loss so far: 0.6241303398684535\n",
      "tensor([0.2561], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2520], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2475], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2461], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2476], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2517], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2545], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2598], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2636], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2661], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "610 out of 3103 batches trained. Average loss so far: 0.6259533928283498\n",
      "tensor([0.2674], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2675], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2704], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2720], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2723], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2716], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2700], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2675], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2642], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2603], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "620 out of 3103 batches trained. Average loss so far: 0.6225265371050812\n",
      "tensor([0.2558], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2509], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2493], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2469], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2439], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2403], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2398], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2421], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2468], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2503], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "630 out of 3103 batches trained. Average loss so far: 0.6243432171276746\n",
      "tensor([0.2525], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2573], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2606], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2627], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2674], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2706], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2725], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2731], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2727], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2750], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "640 out of 3103 batches trained. Average loss so far: 0.625783334330724\n",
      "tensor([0.2800], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2834], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2854], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2901], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2931], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2947], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2949], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2939], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2919], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2888], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "650 out of 3103 batches trained. Average loss so far: 0.6242175795790237\n",
      "tensor([0.2890], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2879], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2859], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2829], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2791], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2785], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2769], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2783], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2824], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2850], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "660 out of 3103 batches trained. Average loss so far: 0.6241275658676014\n",
      "tensor([0.2862], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2901], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2965], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3011], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3082], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3134], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3210], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3307], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3383], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3480], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "670 out of 3103 batches trained. Average loss so far: 0.6286070490736186\n",
      "tensor([0.3597], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3688], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3754], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3842], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3905], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3943], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3960], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4002], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4022], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4022], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "680 out of 3103 batches trained. Average loss so far: 0.6279428397331294\n",
      "tensor([0.4003], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3967], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3917], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3854], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3780], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3697], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3651], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3593], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3526], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3451], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "690 out of 3103 batches trained. Average loss so far: 0.6273484150683656\n",
      "tensor([0.3412], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3362], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3304], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3280], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3287], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3322], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3340], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3384], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3453], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3501], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "700 out of 3103 batches trained. Average loss so far: 0.6292414760878695\n",
      "tensor([0.3528], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3538], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3531], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3509], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3474], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3427], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3371], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3306], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3234], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3156], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "710 out of 3103 batches trained. Average loss so far: 0.626253612601472\n",
      "tensor([0.3074], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3030], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2978], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2960], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2932], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2935], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2966], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3022], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3062], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3084], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "720 out of 3103 batches trained. Average loss so far: 0.6284768231698775\n",
      "tensor([0.3092], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3087], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3069], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3082], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3121], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3186], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3232], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3259], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3313], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3390], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "730 out of 3103 batches trained. Average loss so far: 0.6303795108064582\n",
      "tensor([0.3446], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3481], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3498], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3498], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3526], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3580], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3658], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3712], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3744], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3756], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "740 out of 3103 batches trained. Average loss so far: 0.6303205622835197\n",
      "tensor([0.3750], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3727], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3691], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3686], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3665], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3675], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3667], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3644], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3607], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3557], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "750 out of 3103 batches trained. Average loss so far: 0.6294530313834052\n",
      "tensor([0.3498], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3429], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3397], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3353], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3299], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3237], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3168], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3136], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3093], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3043], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "760 out of 3103 batches trained. Average loss so far: 0.6282433059932995\n",
      "tensor([0.2985], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2922], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2855], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2783], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2710], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2634], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2557], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2480], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2404], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2362], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "770 out of 3103 batches trained. Average loss so far: 0.625619891977805\n",
      "tensor([0.2318], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2270], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2220], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2168], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2115], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2062], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2008], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1985], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1959], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1929], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "780 out of 3103 batches trained. Average loss so far: 0.6224034096039212\n",
      "tensor([0.1897], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1863], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1827], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1790], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1781], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1767], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1778], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1783], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1783], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1777], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "790 out of 3103 batches trained. Average loss so far: 0.6209218531244172\n",
      "tensor([0.1767], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1782], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1789], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1791], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1817], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1835], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1875], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1906], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1928], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1943], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "800 out of 3103 batches trained. Average loss so far: 0.6231749860311715\n",
      "tensor([0.1981], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2010], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2061], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2101], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2131], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2151], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2195], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2228], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2250], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2263], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "810 out of 3103 batches trained. Average loss so far: 0.6232703073655339\n",
      "tensor([0.2301], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2362], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2410], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2445], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2504], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2549], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2580], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2599], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2606], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2603], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "820 out of 3103 batches trained. Average loss so far: 0.6232947487016544\n",
      "tensor([0.2628], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2640], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2642], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2633], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2615], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2589], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2557], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2518], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2474], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2427], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "830 out of 3103 batches trained. Average loss so far: 0.6193731310816591\n",
      "tensor([0.2376], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2322], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2267], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2210], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2152], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2094], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2069], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2039], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2006], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1971], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "840 out of 3103 batches trained. Average loss so far: 0.6181390257851264\n",
      "tensor([0.1964], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1952], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1935], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1914], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1920], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1950], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1971], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1984], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2021], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2048], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "850 out of 3103 batches trained. Average loss so far: 0.6184704639586662\n",
      "tensor([0.2066], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2076], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2078], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2073], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2095], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2107], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2112], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2109], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2099], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2084], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "860 out of 3103 batches trained. Average loss so far: 0.6155677065858997\n",
      "tensor([0.2063], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2071], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2070], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2096], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2112], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2120], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2120], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2113], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2100], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2082], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "870 out of 3103 batches trained. Average loss so far: 0.6142874198241841\n",
      "tensor([0.2058], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2031], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2000], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1966], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1961], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1951], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1966], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1974], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2006], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2029], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "880 out of 3103 batches trained. Average loss so far: 0.6161914658769712\n",
      "tensor([0.2075], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2111], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2136], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2152], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2160], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2159], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2151], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2137], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2118], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2093], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "890 out of 3103 batches trained. Average loss so far: 0.611962885149534\n",
      "tensor([0.2064], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2032], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1997], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1991], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1979], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1963], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1973], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2007], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2032], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2080], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "900 out of 3103 batches trained. Average loss so far: 0.6153271002457223\n",
      "tensor([0.2151], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2208], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2253], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2286], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2309], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2321], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2323], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2318], device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Train the model on the training set\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     16\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def init_hidden(num_layers, num_inputs, hidden_size, device):\n",
    "    return (torch.zeros(num_layers, num_inputs, hidden_size).to(device), torch.zeros(num_layers, num_inputs, hidden_size).to(device))\n",
    "    \n",
    "num_epochs = 15\n",
    "clip = 5\n",
    "# Train the model\n",
    "train_loss_arr = []\n",
    "val_loss_arr = []\n",
    "for epoch in range(num_epochs):\n",
    "    scheduler.step(epoch)\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        h = init_hidden(num_layers, inputs.size(0), hidden_size, device)\n",
    "\n",
    "        # Zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, hn = model(inputs, h)\n",
    "        print(outputs)\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)  # clip the norm of the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i%10==0): \n",
    "            print(i, \"out of\", len(train_loader), \"batches trained. Average loss so far:\", train_loss/(i+1))\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_arr.append(train_loss)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for i, (inputs, labels) in enumerate(validation_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            h = init_hidden(num_layers, inputs.size(0), hidden_size, device)\n",
    "            outputs, hn = model(inputs, h)\n",
    "            loss = criterion(outputs.float(), labels.float())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(validation_loader)\n",
    "        val_loss_arr.append(val_loss)\n",
    "        \n",
    "    # Print the average train and validation losses for this epoch\n",
    "    print(\"Epoch {}/{} Train Loss: {:.4f} Validation Loss: {:.4f}\".format(epoch+1, num_epochs, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b147b2-b58a-4963-aeb6-8317d243de6c",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e07b69b4-9a58-4f49-9935-851b1b0b6c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7101\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-score: 0.0000\n",
      "ROC-AUC score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_model_results(model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            h = init_hidden(num_layers, inputs.size(0), hidden_size, device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, h = model(inputs, h)\n",
    "            preds.append((outputs>.5).cpu().long().numpy())\n",
    "            targets.append(labels.cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(targets, preds)\n",
    "\n",
    "    # Create heatmap with labeled rows and columns\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=categories, yticklabels=categories)\n",
    "\n",
    "    # Add axis labels and title\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion matrix')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # create a list of label names\n",
    "\n",
    "\n",
    "\n",
    "    # show the plot\n",
    "\n",
    "\n",
    "\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    prec = precision_score(targets, preds, zero_division=0)\n",
    "    rec = recall_score(targets, preds)\n",
    "    f1 = f1_score(targets, preds)\n",
    "    roc_auc = roc_auc_score(targets, preds)\n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    print(\"Precision: {:.4f}\".format(prec))\n",
    "    print(\"Recall: {:.4f}\".format(rec))\n",
    "    print(\"F1-score: {:.4f}\".format(f1))\n",
    "    print(\"ROC-AUC score: {:.4f}\".format(roc_auc))\n",
    "\n",
    "\n",
    "print_model_results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564eb8e8-c37d-47f9-ba31-36ed109fbead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
